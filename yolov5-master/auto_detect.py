## ä½¿ç”¨æ–¹æ³•ï¼š

##     æ–‡ä»¶å¤¹ç›‘æ§è¯†åˆ«ï¼špython3 auto_detect.py 

## å®æ—¶è§†é¢‘è¯†åˆ«ï¼šä½¿ç”¨é»˜è®¤æ‘„åƒå¤´ï¼špython3 auto_detect.py --mode video --source 0
## ä½¿ç”¨è§†é¢‘æ–‡ä»¶ï¼š# python scriauto_detectpt.py --mode video --source path/to/video.mp4

## Ultralytics YOLOv5 ğŸš€, AGPL - 3.0 license
import argparse
import os
import time
from pathlib import Path
import torch
import cv2
from models.common import DetectMultiBackend
from utils.general import (
    LOGGER,
    check_img_size,
    non_max_suppression,
    scale_boxes,
    xyxy2xywh,
)
from utils.torch_utils import select_device
from utils.dataloaders import LoadImages
from utils.plots import colors

# å‡è®¾è¿™æ˜¯ä¸­æ–‡ç±»åˆ«åç§°æ˜ å°„ï¼Œä½ å¯ä»¥æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
CHINESE_CLASS_NAMES = {
    'person': 'äºº',
    'bus': 'å…¬äº¤è½¦',
    # å¯ä»¥ç»§ç»­æ·»åŠ å…¶ä»–ç±»åˆ«æ˜ å°„
}


def init_model(opt):
    # åˆå§‹åŒ–æ¨¡å‹
    device = select_device(opt.device)
    model = DetectMultiBackend(opt.weights, device=device, dnn=opt.dnn, data=opt.data, fp16=opt.half)
    stride, names, pt = model.stride, model.names, model.pt
    imgsz = check_img_size(opt.imgsz, s=stride)  # æ£€æŸ¥å›¾åƒå°ºå¯¸
    return model, device, stride, names, pt, imgsz


@torch.no_grad()
def detect_folder(opt, model, device, stride, names, pt, imgsz):
    source_dir = Path(opt.source)
    output_dir = Path(opt.output)
    output_dir.mkdir(parents=True, exist_ok=True)  # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹

    processed_files = set()  # è®°å½•å·²å¤„ç†çš„æ–‡ä»¶
    img_formats = [f".{f}" for f in ['bmp', 'dng', 'jpeg', 'jpg', 'mpo', 'png',
                                      'tif', 'tiff', 'webp', 'pfm']]  # æ”¯æŒçš„å›¾åƒæ ¼å¼

    LOGGER.info(f"å¼€å§‹ç›‘æ§æ–‡ä»¶å¤¹: {source_dir}")
    LOGGER.info(f"ç­‰å¾…æ–°å›¾ç‰‡å­˜å…¥ï¼ŒæŒ‰Ctrl+Cåœæ­¢...")

    try:
        while True:
            # è·å–å½“å‰æ–‡ä»¶å¤¹å†…æ‰€æœ‰ç¬¦åˆæ ¼å¼çš„å›¾ç‰‡æ–‡ä»¶
            current_files = [f for f in source_dir.glob('*')
                             if f.suffix.lower() in img_formats and f.is_file()]

            # è¿‡æ»¤æœªå¤„ç†çš„æ–°æ–‡ä»¶ï¼ˆæŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œç¡®ä¿æ–°æ–‡ä»¶å…ˆå¤„ç†ï¼‰
            new_files = [f for f in current_files if f.name not in processed_files]
            new_files.sort(key=lambda x: x.stat().st_mtime)  # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº

            for img_path in new_files:
                try:
                    processed_files.add(img_path.name)  # æ ‡è®°ä¸ºå·²å¤„ç†
                    LOGGER.info(f"\næ£€æµ‹æ–°å›¾ç‰‡: {img_path.name}")

                    # å•å›¾ç‰‡å¤„ç†æµç¨‹
                    dataset = LoadImages(str(img_path), img_size=imgsz, stride=stride, auto=pt)
                    for path, im, im0s, _, _ in dataset:
                        im = torch.from_numpy(im).to(device)
                        im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32
                        im /= 255  # 0 - 255 to 0.0 - 1.0
                        if len(im.shape) == 3:
                            im = im[None]  # æ‰©å±•batchç»´åº¦

                        # è®°å½•æ¨ç†å¼€å§‹æ—¶é—´
                        start_time = time.time()

                        # æ¨ç†
                        pred = model(im, augment=opt.augment, visualize=False)

                        # è®°å½•æ¨ç†ç»“æŸæ—¶é—´
                        end_time = time.time()
                        inference_time = end_time - start_time
                        LOGGER.info(f"è¯†åˆ«ç”¨æ—¶: {inference_time:.4f} ç§’")

                        # NMS
                        pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres,
                                                   opt.classes, opt.agnostic_nms, opt.max_det)

                        # å¤„ç†æ£€æµ‹ç»“æœ
                        results = []
                        im0 = im0s.copy()
                        for det in pred:
                            if len(det):
                                det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0s.shape).round()

                                # æ”¶é›†æ£€æµ‹ç»“æœ
                                for *xyxy, conf, cls in det:
                                    c = int(cls)
                                    original_name = names[c]
                                    chinese_name = CHINESE_CLASS_NAMES.get(original_name, original_name)
                                    label = f'{chinese_name} {conf:.2f}'
                                    results.append((chinese_name, f"{conf:.2f}"))

                                    # æ‰‹åŠ¨ç»˜åˆ¶è¾¹ç•Œæ¡†å’Œæ ‡ç­¾
                                    xyxy = [int(i) for i in xyxy]
                                    cv2.rectangle(im0, (xyxy[0], xyxy[1]), (xyxy[2], xyxy[3]), colors(c, True), 2)
                                    cv2.putText(im0, label, (xyxy[0], xyxy[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,
                                                colors(c, True), 2)

                                # æ‰“å°ç»“æœ
                                class_counts = {}
                                for cls_name, _ in results:
                                    class_counts[cls_name] = class_counts.get(cls_name, 0) + 1

                                # ä¿®æ­£ä¸­æ–‡è¾“å‡º
                                print_str_list = []
                                for k, v in class_counts.items():
                                    if k == 'äºº':
                                        print_str_list.append(f"{v} {k}")
                                    elif k == 'å…¬äº¤è½¦':
                                        print_str_list.append(f"{v} {k}")
                                    else:
                                        print_str_list.append(f"{v} {k}{'s' if v > 1 and k not in ['äºº', 'å…¬äº¤è½¦'] else ''}")
                                print_str = ", ".join(print_str_list)

                                LOGGER.info(f"æ£€æµ‹ç»“æœ: {print_str}")
                            else:
                                print_str = "æœªæ£€æµ‹åˆ°ç›®æ ‡"
                                LOGGER.info(print_str)

                            # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
                            output_file = output_dir / (img_path.stem + ".txt")
                            with open(output_file, 'w') as f:
                                f.write(print_str)
                            LOGGER.info(f"æ£€æµ‹ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

                            # ä¿å­˜æ ‡æ³¨åçš„å›¾ç‰‡
                            output_img_path = output_dir / img_path.name
                            cv2.imwrite(str(output_img_path), im0)
                            LOGGER.info(f"æ ‡æ³¨å›¾ç‰‡å·²ä¿å­˜åˆ°: {output_img_path}")
                except AssertionError as e:
                    LOGGER.error(f"å¤„ç†å›¾ç‰‡ {img_path.name} æ—¶å‡ºé”™: {e}")
                except Exception as e:
                    LOGGER.error(f"å¤„ç†å›¾ç‰‡ {img_path.name} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

            # ç­‰å¾…æŒ‡å®šé—´éš”åé‡æ–°æ£€æŸ¥
            time.sleep(opt.watch_interval)

    except KeyboardInterrupt:
        LOGGER.info("\næ£€æµ‹åœæ­¢")


@torch.no_grad()
def detect_video(opt, model, device, stride, names, pt, imgsz):
    # æ‰“å¼€è§†é¢‘æµ
    if opt.source.isdigit():
        cap = cv2.VideoCapture(int(opt.source))  # æ‘„åƒå¤´è®¾å¤‡
    else:
        cap = cv2.VideoCapture(opt.source)  # è§†é¢‘æ–‡ä»¶

    if not cap.isOpened():
        LOGGER.error("æ— æ³•æ‰“å¼€è§†é¢‘æµ")
        return

    LOGGER.info("å¼€å§‹å®æ—¶ç›®æ ‡æ£€æµ‹ï¼ŒæŒ‰ 'q' é”®é€€å‡º...")

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                LOGGER.info("è§†é¢‘æµç»“æŸ")
                break

            # å•å¸§å¤„ç†æµç¨‹
            im = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            im = cv2.resize(im, (imgsz[0], imgsz[1]))
            im = torch.from_numpy(im).to(device)
            im = im.permute(2, 0, 1).unsqueeze(0).float() / 255.0  # uint8 to fp32

            # è®°å½•æ¨ç†å¼€å§‹æ—¶é—´
            start_time = time.time()

            # æ¨ç†
            pred = model(im, augment=opt.augment, visualize=False)

            # è®°å½•æ¨ç†ç»“æŸæ—¶é—´
            end_time = time.time()
            inference_time = end_time - start_time
            LOGGER.info(f"è¯†åˆ«ç”¨æ—¶: {inference_time:.4f} ç§’")

            # NMS
            pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres,
                                       opt.classes, opt.agnostic_nms, opt.max_det)

            # å¤„ç†æ£€æµ‹ç»“æœ
            results = []
            im0 = frame.copy()
            for det in pred:
                if len(det):
                    det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0.shape).round()

                    # æ”¶é›†æ£€æµ‹ç»“æœ
                    for *xyxy, conf, cls in det:
                        c = int(cls)
                        original_name = names[c]
                        chinese_name = CHINESE_CLASS_NAMES.get(original_name, original_name)
                        label = f'{chinese_name} {conf:.2f}'
                        results.append((chinese_name, f"{conf:.2f}"))

                        # æ‰‹åŠ¨ç»˜åˆ¶è¾¹ç•Œæ¡†å’Œæ ‡ç­¾
                        xyxy = [int(i) for i in xyxy]
                        cv2.rectangle(im0, (xyxy[0], xyxy[1]), (xyxy[2], xyxy[3]), colors(c, True), 2)
                        cv2.putText(im0, label, (xyxy[0], xyxy[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,
                                    colors(c, True), 2)

                    # æ‰“å°ç»“æœ
                    class_counts = {}
                    for cls_name, _ in results:
                        class_counts[cls_name] = class_counts.get(cls_name, 0) + 1

                    # ä¿®æ­£ä¸­æ–‡è¾“å‡º
                    print_str_list = []
                    for k, v in class_counts.items():
                        if k == 'äºº':
                            print_str_list.append(f"{v} {k}")
                        elif k == 'å…¬äº¤è½¦':
                            print_str_list.append(f"{v} {k}")
                        else:
                            print_str_list.append(f"{v} {k}{'s' if v > 1 and k not in ['äºº', 'å…¬äº¤è½¦'] else ''}")
                    print_str = ", ".join(print_str_list)

                    LOGGER.info(f"æ£€æµ‹ç»“æœ: {print_str}")
                else:
                    print_str = "æœªæ£€æµ‹åˆ°ç›®æ ‡"
                    LOGGER.info(print_str)

            # æ˜¾ç¤ºç»“æœ
            cv2.imshow('YOLOv5 Real-time Detection', im0)

            # æŒ‰ 'q' é”®é€€å‡º
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

    except KeyboardInterrupt:
        LOGGER.info("\næ£€æµ‹åœæ­¢")
    finally:
        cap.release()
        cv2.destroyAllWindows()


def parse_opt():
    parser = argparse.ArgumentParser()
    parser.add_argument("--weights", nargs="+", type=str, default="yolov5s.pt", help="æ¨¡å‹æƒé‡è·¯å¾„")
    parser.add_argument("--source", type=str, default="data/images", help="ç›‘æ§çš„æ–‡ä»¶å¤¹è·¯å¾„æˆ–è§†é¢‘æµæºï¼Œ0 è¡¨ç¤ºé»˜è®¤æ‘„åƒå¤´ï¼Œä¹Ÿå¯ä»¥æ˜¯è§†é¢‘æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", type=str, default="output_results", help="ä¿å­˜æ£€æµ‹ç»“æœå’Œå›¾ç‰‡çš„æ–‡ä»¶å¤¹è·¯å¾„")
    parser.add_argument("--watch-interval", type=int, default=1,
                        help="æ£€æŸ¥æ–‡ä»¶å¤¹çš„æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤1ç§’")
    parser.add_argument("--imgsz", nargs="+", type=int, default=[640], help="æ¨ç†å°ºå¯¸ (h,w)")
    parser.add_argument("--conf-thres", type=float, default=0.25, help="ç½®ä¿¡åº¦é˜ˆå€¼")
    parser.add_argument("--iou-thres", type=float, default=0.45, help="NMS IoUé˜ˆå€¼")
    parser.add_argument("--device", default="", help="è®¾å¤‡ (cpu, 0, 1, ...)")
    parser.add_argument("--half", action="store_true", help="ä½¿ç”¨FP16åŠç²¾åº¦æ¨ç†")
    parser.add_argument("--dnn", action="store_true", help="ä½¿ç”¨OpenCV DNNè¿›è¡ŒONNXæ¨ç†")
    parser.add_argument("--data", type=str, default="data/coco128.yaml", help="æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--augment", action="store_true", help="æ˜¯å¦ä½¿ç”¨æ•°æ®å¢å¼ºè¿›è¡Œæ¨ç†")
    parser.add_argument("--classes", nargs="+", type=int, help="è¿‡æ»¤æŒ‡å®šç±»åˆ«çš„æ£€æµ‹ç»“æœï¼Œä¾‹å¦‚ --classes 0 2 3 è¡¨ç¤ºåªæ£€æµ‹ç±»åˆ«0ã€2ã€3")
    parser.add_argument("--agnostic_nms", action="store_true", help="æ˜¯å¦ä½¿ç”¨ç±»åˆ«æ— å…³çš„NMS")
    parser.add_argument("--max_det", type=int, default=1000, help="æ¯å¼ å›¾ç‰‡çš„æœ€å¤§æ£€æµ‹æ•°é‡")
    parser.add_argument("--mode", type=str, default="folder", choices=["folder", "video"],
                        help="é€‰æ‹©è¯†åˆ«æ¨¡å¼ï¼Œ'folder' è¡¨ç¤ºç›‘æ§æ–‡ä»¶å¤¹ï¼Œ'video' è¡¨ç¤ºå®æ—¶è§†é¢‘è¯†åˆ«")
    opt = parser.parse_args()
    opt.imgsz *= 2 if len(opt.imgsz) == 1 else 1  # æ‰©å±•å°ºå¯¸æ ¼å¼
    return opt


if __name__ == "__main__":
    opt = parse_opt()
    model, device, stride, names, pt, imgsz = init_model(opt)

    if opt.mode == "folder":
        detect_folder(opt, model, device, stride, names, pt, imgsz)
    elif opt.mode == "video":
        detect_video(opt, model, device, stride, names, pt, imgsz)





























## å¯ä»¥ä¸éœ€è¦roscore
# # # Ultralytics YOLOv5 ğŸš€, AGPL - 3.0 license
# import argparse
# import os
# import time
# from pathlib import Path
# import torch
# import cv2
# from models.common import DetectMultiBackend
# from utils.general import (
#     LOGGER,
#     check_img_size,
#     non_max_suppression,
#     scale_boxes,
#     xyxy2xywh,
# )
# from utils.torch_utils import select_device
# from utils.dataloaders import LoadImages
# from utils.plots import colors

# # å‡è®¾è¿™æ˜¯ä¸­æ–‡ç±»åˆ«åç§°æ˜ å°„ï¼Œä½ å¯ä»¥æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
# CHINESE_CLASS_NAMES = {
#     'person': 'äºº',
#     'bus': 'å…¬äº¤è½¦',
#     # å¯ä»¥ç»§ç»­æ·»åŠ å…¶ä»–ç±»åˆ«æ˜ å°„
# }


# def init_model(opt):
#     # åˆå§‹åŒ–æ¨¡å‹
#     device = select_device(opt.device)
#     model = DetectMultiBackend(opt.weights, device=device, dnn=opt.dnn, data=opt.data, fp16=opt.half)
#     stride, names, pt = model.stride, model.names, model.pt
#     imgsz = check_img_size(opt.imgsz, s=stride)  # æ£€æŸ¥å›¾åƒå°ºå¯¸
#     return model, device, stride, names, pt, imgsz


# @torch.no_grad()
# def main(opt):
#     # æå‰åˆå§‹åŒ–æ¨¡å‹
#     model, device, stride, names, pt, imgsz = init_model(opt)

#     source_dir = Path(opt.source)
#     output_dir = Path(opt.output)
#     output_dir.mkdir(parents=True, exist_ok=True)  # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹

#     processed_files = set()  # è®°å½•å·²å¤„ç†çš„æ–‡ä»¶
#     img_formats = [f".{f}" for f in ['bmp', 'dng', 'jpeg', 'jpg', 'mpo', 'png',
#                                       'tif', 'tiff', 'webp', 'pfm']]  # æ”¯æŒçš„å›¾åƒæ ¼å¼

#     LOGGER.info(f"å¼€å§‹ç›‘æ§æ–‡ä»¶å¤¹: {source_dir}")
#     LOGGER.info(f"ç­‰å¾…æ–°å›¾ç‰‡å­˜å…¥ï¼ŒæŒ‰Ctrl+Cåœæ­¢...")

#     try:
#         while True:
#             # è·å–å½“å‰æ–‡ä»¶å¤¹å†…æ‰€æœ‰ç¬¦åˆæ ¼å¼çš„å›¾ç‰‡æ–‡ä»¶
#             current_files = [f for f in source_dir.glob('*')
#                              if f.suffix.lower() in img_formats and f.is_file()]

#             # è¿‡æ»¤æœªå¤„ç†çš„æ–°æ–‡ä»¶ï¼ˆæŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œç¡®ä¿æ–°æ–‡ä»¶å…ˆå¤„ç†ï¼‰
#             new_files = [f for f in current_files if f.name not in processed_files]
#             new_files.sort(key=lambda x: x.stat().st_mtime)  # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº

#             for img_path in new_files:
#                 try:
#                     processed_files.add(img_path.name)  # æ ‡è®°ä¸ºå·²å¤„ç†
#                     LOGGER.info(f"\næ£€æµ‹æ–°å›¾ç‰‡: {img_path.name}")

#                     # å•å›¾ç‰‡å¤„ç†æµç¨‹
#                     dataset = LoadImages(str(img_path), img_size=imgsz, stride=stride, auto=pt)
#                     for path, im, im0s, _, _ in dataset:
#                         im = torch.from_numpy(im).to(device)
#                         im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32
#                         im /= 255  # 0 - 255 to 0.0 - 1.0
#                         if len(im.shape) == 3:
#                             im = im[None]  # æ‰©å±•batchç»´åº¦

#                         # è®°å½•æ¨ç†å¼€å§‹æ—¶é—´
#                         start_time = time.time()

#                         # æ¨ç†
#                         pred = model(im, augment=opt.augment, visualize=False)

#                         # è®°å½•æ¨ç†ç»“æŸæ—¶é—´
#                         end_time = time.time()
#                         inference_time = end_time - start_time
#                         LOGGER.info(f"è¯†åˆ«ç”¨æ—¶: {inference_time:.4f} ç§’")

#                         # NMS
#                         pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres,
#                                                    opt.classes, opt.agnostic_nms, opt.max_det)

#                         # å¤„ç†æ£€æµ‹ç»“æœ
#                         results = []
#                         im0 = im0s.copy()
#                         for det in pred:
#                             if len(det):
#                                 det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0s.shape).round()

#                                 # æ”¶é›†æ£€æµ‹ç»“æœ
#                                 for *xyxy, conf, cls in det:
#                                     c = int(cls)
#                                     original_name = names[c]
#                                     chinese_name = CHINESE_CLASS_NAMES.get(original_name, original_name)
#                                     label = f'{chinese_name} {conf:.2f}'
#                                     results.append((chinese_name, f"{conf:.2f}"))

#                                     # æ‰‹åŠ¨ç»˜åˆ¶è¾¹ç•Œæ¡†å’Œæ ‡ç­¾
#                                     xyxy = [int(i) for i in xyxy]
#                                     cv2.rectangle(im0, (xyxy[0], xyxy[1]), (xyxy[2], xyxy[3]), colors(c, True), 2)
#                                     cv2.putText(im0, label, (xyxy[0], xyxy[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,
#                                                 colors(c, True), 2)

#                                 # æ‰“å°ç»“æœ
#                                 class_counts = {}
#                                 for cls_name, _ in results:
#                                     class_counts[cls_name] = class_counts.get(cls_name, 0) + 1

#                                 # ä¿®æ­£ä¸­æ–‡è¾“å‡º
#                                 print_str_list = []
#                                 for k, v in class_counts.items():
#                                     if k == 'äºº':
#                                         print_str_list.append(f"{v} {k}")
#                                     elif k == 'å…¬äº¤è½¦':
#                                         print_str_list.append(f"{v} {k}")
#                                     else:
#                                         print_str_list.append(f"{v} {k}{'s' if v > 1 and k not in ['äºº', 'å…¬äº¤è½¦'] else ''}")
#                                 print_str = ", ".join(print_str_list)

#                                 LOGGER.info(f"æ£€æµ‹ç»“æœ: {print_str}")
#                             else:
#                                 print_str = "æœªæ£€æµ‹åˆ°ç›®æ ‡"
#                                 LOGGER.info(print_str)

#                             # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
#                             output_file = output_dir / (img_path.stem + ".txt")
#                             with open(output_file, 'w') as f:
#                                 f.write(print_str)
#                             LOGGER.info(f"æ£€æµ‹ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

#                             # ä¿å­˜æ ‡æ³¨åçš„å›¾ç‰‡
#                             output_img_path = output_dir / img_path.name
#                             cv2.imwrite(str(output_img_path), im0)
#                             LOGGER.info(f"æ ‡æ³¨å›¾ç‰‡å·²ä¿å­˜åˆ°: {output_img_path}")
#                 except AssertionError as e:
#                     LOGGER.error(f"å¤„ç†å›¾ç‰‡ {img_path.name} æ—¶å‡ºé”™: {e}")
#                 except Exception as e:
#                     LOGGER.error(f"å¤„ç†å›¾ç‰‡ {img_path.name} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

#             # ç­‰å¾…æŒ‡å®šé—´éš”åé‡æ–°æ£€æŸ¥
#             time.sleep(opt.watch_interval)

#     except KeyboardInterrupt:
#         LOGGER.info("\næ£€æµ‹åœæ­¢")


# def parse_opt():
#     parser = argparse.ArgumentParser()
#     parser.add_argument("--weights", nargs="+", type=str, default="yolov5s.pt", help="æ¨¡å‹æƒé‡è·¯å¾„")
#     parser.add_argument("--source", type=str, default="data/images", help="ç›‘æ§çš„æ–‡ä»¶å¤¹è·¯å¾„")
#     parser.add_argument("--output", type=str, default="output_results", help="ä¿å­˜æ£€æµ‹ç»“æœå’Œå›¾ç‰‡çš„æ–‡ä»¶å¤¹è·¯å¾„")
#     parser.add_argument("--watch-interval", type=int, default=1,
#                         help="æ£€æŸ¥æ–‡ä»¶å¤¹çš„æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤1ç§’")
#     parser.add_argument("--imgsz", nargs="+", type=int, default=[640], help="æ¨ç†å°ºå¯¸ (h,w)")
#     parser.add_argument("--conf-thres", type=float, default=0.25, help="ç½®ä¿¡åº¦é˜ˆå€¼")
#     parser.add_argument("--iou-thres", type=float, default=0.45, help="NMS IoUé˜ˆå€¼")
#     parser.add_argument("--device", default="", help="è®¾å¤‡ (cpu, 0, 1, ...)")
#     parser.add_argument("--half", action="store_true", help="ä½¿ç”¨FP16åŠç²¾åº¦æ¨ç†")
#     parser.add_argument("--dnn", action="store_true", help="ä½¿ç”¨OpenCV DNNè¿›è¡ŒONNXæ¨ç†")
#     parser.add_argument("--data", type=str, default="data/coco128.yaml", help="æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„")
#     parser.add_argument("--augment", action="store_true", help="æ˜¯å¦ä½¿ç”¨æ•°æ®å¢å¼ºè¿›è¡Œæ¨ç†")
#     parser.add_argument("--classes", nargs="+", type=int, help="è¿‡æ»¤æŒ‡å®šç±»åˆ«çš„æ£€æµ‹ç»“æœï¼Œä¾‹å¦‚ --classes 0 2 3 è¡¨ç¤ºåªæ£€æµ‹ç±»åˆ«0ã€2ã€3")
#     parser.add_argument("--agnostic_nms", action="store_true", help="æ˜¯å¦ä½¿ç”¨ç±»åˆ«æ— å…³çš„NMS")
#     parser.add_argument("--max_det", type=int, default=1000, help="æ¯å¼ å›¾ç‰‡çš„æœ€å¤§æ£€æµ‹æ•°é‡")
#     opt = parser.parse_args()
#     opt.imgsz *= 2 if len(opt.imgsz) == 1 else 1  # æ‰©å±•å°ºå¯¸æ ¼å¼
#     print_args(vars(opt))
#     return opt


# def print_args(args):
#     """æ‰“å°å‚æ•°é…ç½®"""
#     LOGGER.info("\nå‚æ•°é…ç½®:")
#     for k, v in args.items():
#         LOGGER.info(f"  {k}: {v}")
#     LOGGER.info("\n")


# if __name__ == "__main__":
#     opt = parse_opt()
#     main(opt)



























## éœ€è¦roscore
# # # Ultralytics YOLOv5 ğŸš€, AGPL - 3.0 license
# import argparse
# import os
# import time
# from pathlib import Path
# import torch
# import cv2
# from models.common import DetectMultiBackend
# from utils.general import (
#     LOGGER,
#     check_img_size,
#     non_max_suppression,
#     scale_boxes,
#     xyxy2xywh,
# )
# from utils.torch_utils import select_device
# from utils.dataloaders import LoadImages
# from utils.plots import colors

# # å‡è®¾è¿™æ˜¯ä¸­æ–‡ç±»åˆ«åç§°æ˜ å°„ï¼Œä½ å¯ä»¥æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
# CHINESE_CLASS_NAMES = {
#     'person': 'äºº',
#     'bus': 'å…¬äº¤è½¦',
#     # å¯ä»¥ç»§ç»­æ·»åŠ å…¶ä»–ç±»åˆ«æ˜ å°„
# }


# def init_model(opt):
#     # åˆå§‹åŒ–æ¨¡å‹
#     device = select_device(opt.device)
#     model = DetectMultiBackend(opt.weights, device=device, dnn=opt.dnn, data=opt.data, fp16=opt.half)
#     stride, names, pt = model.stride, model.names, model.pt
#     imgsz = check_img_size(opt.imgsz, s=stride)  # æ£€æŸ¥å›¾åƒå°ºå¯¸
#     return model, device, stride, names, pt, imgsz


# @torch.no_grad()
# def main(opt):
#     # æå‰åˆå§‹åŒ–æ¨¡å‹
#     model, device, stride, names, pt, imgsz = init_model(opt)

#     source_dir = Path(opt.source)
#     output_dir = Path(opt.output)
#     output_dir.mkdir(parents=True, exist_ok=True)  # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹

#     processed_files = set()  # è®°å½•å·²å¤„ç†çš„æ–‡ä»¶
#     img_formats = [f".{f}" for f in ['bmp', 'dng', 'jpeg', 'jpg', 'mpo', 'png',
#                                       'tif', 'tiff', 'webp', 'pfm']]  # æ”¯æŒçš„å›¾åƒæ ¼å¼

#     LOGGER.info(f"å¼€å§‹ç›‘æ§æ–‡ä»¶å¤¹: {source_dir}")
#     LOGGER.info(f"ç­‰å¾…æ–°å›¾ç‰‡å­˜å…¥ï¼ŒæŒ‰Ctrl+Cåœæ­¢...")

#     try:
#         while True:
#             # è·å–å½“å‰æ–‡ä»¶å¤¹å†…æ‰€æœ‰ç¬¦åˆæ ¼å¼çš„å›¾ç‰‡æ–‡ä»¶
#             current_files = [f for f in source_dir.glob('*')
#                              if f.suffix.lower() in img_formats and f.is_file()]

#             # è¿‡æ»¤æœªå¤„ç†çš„æ–°æ–‡ä»¶ï¼ˆæŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œç¡®ä¿æ–°æ–‡ä»¶å…ˆå¤„ç†ï¼‰
#             new_files = [f for f in current_files if f.name not in processed_files]
#             new_files.sort(key=lambda x: x.stat().st_mtime)  # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº

#             for img_path in new_files:
#                 try:
#                     processed_files.add(img_path.name)  # æ ‡è®°ä¸ºå·²å¤„ç†
#                     LOGGER.info(f"\næ£€æµ‹æ–°å›¾ç‰‡: {img_path.name}")

#                     # å•å›¾ç‰‡å¤„ç†æµç¨‹
#                     dataset = LoadImages(str(img_path), img_size=imgsz, stride=stride, auto=pt)
#                     for path, im, im0s, _, _ in dataset:
#                         im = torch.from_numpy(im).to(device)
#                         im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32
#                         im /= 255  # 0 - 255 to 0.0 - 1.0
#                         if len(im.shape) == 3:
#                             im = im[None]  # æ‰©å±•batchç»´åº¦

#                         # è®°å½•æ¨ç†å¼€å§‹æ—¶é—´
#                         start_time = time.time()

#                         # æ¨ç†
#                         pred = model(im, augment=opt.augment, visualize=False)

#                         # è®°å½•æ¨ç†ç»“æŸæ—¶é—´
#                         end_time = time.time()
#                         inference_time = end_time - start_time
#                         LOGGER.info(f"è¯†åˆ«ç”¨æ—¶: {inference_time:.4f} ç§’")

#                         # NMS
#                         pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres,
#                                                    opt.classes, opt.agnostic_nms, opt.max_det)

#                         # å¤„ç†æ£€æµ‹ç»“æœ
#                         results = []
#                         im0 = im0s.copy()
#                         for det in pred:
#                             if len(det):
#                                 det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0s.shape).round()

#                                 # æ”¶é›†æ£€æµ‹ç»“æœ
#                                 for *xyxy, conf, cls in det:
#                                     c = int(cls)
#                                     original_name = names[c]
#                                     chinese_name = CHINESE_CLASS_NAMES.get(original_name, original_name)
#                                     label = f'{chinese_name} {conf:.2f}'
#                                     results.append((chinese_name, f"{conf:.2f}"))

#                                     # æ‰‹åŠ¨ç»˜åˆ¶è¾¹ç•Œæ¡†å’Œæ ‡ç­¾
#                                     xyxy = [int(i) for i in xyxy]
#                                     cv2.rectangle(im0, (xyxy[0], xyxy[1]), (xyxy[2], xyxy[3]), colors(c, True), 2)
#                                     cv2.putText(im0, label, (xyxy[0], xyxy[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,
#                                                 colors(c, True), 2)

#                                 # æ‰“å°ç»“æœ
#                                 class_counts = {}
#                                 for cls_name, _ in results:
#                                     class_counts[cls_name] = class_counts.get(cls_name, 0) + 1

#                                 # ä¿®æ­£ä¸­æ–‡è¾“å‡º
#                                 print_str_list = []
#                                 for k, v in class_counts.items():
#                                     if k == 'äºº':
#                                         print_str_list.append(f"{v} {k}")
#                                     elif k == 'å…¬äº¤è½¦':
#                                         print_str_list.append(f"{v} {k}")
#                                     else:
#                                         print_str_list.append(f"{v} {k}{'s' if v > 1 and k not in ['äºº', 'å…¬äº¤è½¦'] else ''}")
#                                 print_str = ", ".join(print_str_list)

#                                 LOGGER.info(f"æ£€æµ‹ç»“æœ: {print_str}")
#                             else:
#                                 print_str = "æœªæ£€æµ‹åˆ°ç›®æ ‡"
#                                 LOGGER.info(print_str)

#                             # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
#                             output_file = output_dir / (img_path.stem + ".txt")
#                             with open(output_file, 'w') as f:
#                                 f.write(print_str)
#                             LOGGER.info(f"æ£€æµ‹ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

#                             # ä¿å­˜æ ‡æ³¨åçš„å›¾ç‰‡
#                             output_img_path = output_dir / img_path.name
#                             cv2.imwrite(str(output_img_path), im0)
#                             LOGGER.info(f"æ ‡æ³¨å›¾ç‰‡å·²ä¿å­˜åˆ°: {output_img_path}")
#                 except AssertionError as e:
#                     LOGGER.error(f"å¤„ç†å›¾ç‰‡ {img_path.name} æ—¶å‡ºé”™: {e}")
#                 except Exception as e:
#                     LOGGER.error(f"å¤„ç†å›¾ç‰‡ {img_path.name} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

#             # ç­‰å¾…æŒ‡å®šé—´éš”åé‡æ–°æ£€æŸ¥
#             time.sleep(opt.watch_interval)

#     except KeyboardInterrupt:
#         LOGGER.info("\næ£€æµ‹åœæ­¢")


# def parse_opt():
#     parser = argparse.ArgumentParser()
#     parser.add_argument("--weights", nargs="+", type=str, default="yolov5s.pt", help="æ¨¡å‹æƒé‡è·¯å¾„")
#     parser.add_argument("--source", type=str, default="data/images", help="ç›‘æ§çš„æ–‡ä»¶å¤¹è·¯å¾„")
#     parser.add_argument("--output", type=str, default="output_results", help="ä¿å­˜æ£€æµ‹ç»“æœå’Œå›¾ç‰‡çš„æ–‡ä»¶å¤¹è·¯å¾„")
#     parser.add_argument("--watch-interval", type=int, default=1,
#                         help="æ£€æŸ¥æ–‡ä»¶å¤¹çš„æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤1ç§’")
#     parser.add_argument("--imgsz", nargs="+", type=int, default=[640], help="æ¨ç†å°ºå¯¸ (h,w)")
#     parser.add_argument("--conf-thres", type=float, default=0.25, help="ç½®ä¿¡åº¦é˜ˆå€¼")
#     parser.add_argument("--iou-thres", type=float, default=0.45, help="NMS IoUé˜ˆå€¼")
#     parser.add_argument("--device", default="", help="è®¾å¤‡ (cpu, 0, 1, ...)")
#     parser.add_argument("--half", action="store_true", help="ä½¿ç”¨FP16åŠç²¾åº¦æ¨ç†")
#     parser.add_argument("--dnn", action="store_true", help="ä½¿ç”¨OpenCV DNNè¿›è¡ŒONNXæ¨ç†")
#     parser.add_argument("--data", type=str, default="data/coco128.yaml", help="æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„")
#     parser.add_argument("--augment", action="store_true", help="æ˜¯å¦ä½¿ç”¨æ•°æ®å¢å¼ºè¿›è¡Œæ¨ç†")
#     parser.add_argument("--classes", nargs="+", type=int, help="è¿‡æ»¤æŒ‡å®šç±»åˆ«çš„æ£€æµ‹ç»“æœï¼Œä¾‹å¦‚ --classes 0 2 3 è¡¨ç¤ºåªæ£€æµ‹ç±»åˆ«0ã€2ã€3")
#     parser.add_argument("--agnostic_nms", action="store_true", help="æ˜¯å¦ä½¿ç”¨ç±»åˆ«æ— å…³çš„NMS")
#     parser.add_argument("--max_det", type=int, default=1000, help="æ¯å¼ å›¾ç‰‡çš„æœ€å¤§æ£€æµ‹æ•°é‡")
#     opt = parser.parse_args()
#     opt.imgsz *= 2 if len(opt.imgsz) == 1 else 1  # æ‰©å±•å°ºå¯¸æ ¼å¼
#     print_args(vars(opt))
#     return opt


# def print_args(args):
#     """æ‰“å°å‚æ•°é…ç½®"""
#     LOGGER.info("\nå‚æ•°é…ç½®:")
#     for k, v in args.items():
#         LOGGER.info(f"  {k}: {v}")
#     LOGGER.info("\n")


# if __name__ == "__main__":
#     opt = parse_opt()
#     main(opt)
